{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37cfc8a5",
   "metadata": {},
   "source": [
    "# 01 â€” Data Preprocessing & EDA\n",
    "\n",
    "This notebook:\n",
    "- Loads the UCI Heart Disease dataset from `data/heart_disease.csv`\n",
    "- Handles missing values\n",
    "- Encodes categorical variables\n",
    "- Scales numeric features\n",
    "- Performs EDA (histograms, correlation)\n",
    "- Splits data into train/test\n",
    "- Saves `data/processed/train.csv`, `data/processed/test.csv` (optional) and `results/eda_summary.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883179bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "DATA_PATH = Path(\"../data/heart_disease.csv\")\n",
    "\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(\"Please place the dataset at data/heart_disease.csv\")\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb814aee",
   "metadata": {},
   "source": [
    "## Basic Info & Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d17da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.info())\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d748dd",
   "metadata": {},
   "source": [
    "## Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7b7c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms for numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "for col in numeric_cols:\n",
    "    plt.figure()\n",
    "    df[col].hist(bins=30)\n",
    "    plt.title(f\"Histogram: {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n",
    "\n",
    "# Correlation matrix (numeric only)\n",
    "corr = df[numeric_cols].corr()\n",
    "plt.figure()\n",
    "plt.imshow(corr, cmap=\"viridis\", aspect=\"auto\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Correlation Heatmap (numeric columns)\")\n",
    "plt.xticks(range(len(numeric_cols)), numeric_cols, rotation=90)\n",
    "plt.yticks(range(len(numeric_cols)), numeric_cols)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d344451",
   "metadata": {},
   "source": [
    "## Train/Test Split & Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a7f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume target column name variations:\n",
    "possible_targets = [\"target\", \"num\", \"condition\", \"disease\"]\n",
    "target = None\n",
    "for t in possible_targets:\n",
    "    if t in df.columns:\n",
    "        target = t\n",
    "        break\n",
    "if target is None:\n",
    "    raise ValueError(\"Could not find target column. Rename your label column to 'target' or 'num'.\")\n",
    "\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_cols),\n",
    "        (\"cat\", categorical_transformer, cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y if len(np.unique(y))<=20 else None\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \" Test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90a21d6",
   "metadata": {},
   "source": [
    "## Save train/test indices (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3d5c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path(\"../data/processed\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "pd.concat([X_train, y_train], axis=1).to_csv(out_dir/\"train.csv\", index=False)\n",
    "pd.concat([X_test, y_test], axis=1).to_csv(out_dir/\"test.csv\", index=False)\n",
    "\n",
    "with open(\"../results/eda_summary.txt\", \"w\") as f:\n",
    "    f.write(f\"Rows: {len(df)}\\nColumns: {len(df.columns)}\\nTarget: {target}\\n\")\n",
    "    f.write(f\"Numeric: {len(num_cols)}; Categorical: {len(cat_cols)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508bc36f",
   "metadata": {},
   "source": [
    "## Export preprocessing object (for reuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9d064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(preprocessor, \"../models/preprocessor.pkl\")\n",
    "print(\"Saved ../models/preprocessor.pkl\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
