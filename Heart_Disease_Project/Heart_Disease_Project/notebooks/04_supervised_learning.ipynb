{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "960232a9",
   "metadata": {},
   "source": [
    "# 04 â€” Supervised Learning\n",
    "\n",
    "Train baseline classifiers:\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- SVM\n",
    "\n",
    "Evaluate: Accuracy, Precision, Recall, F1, ROC/AUC.\n",
    "Save metrics to `results/evaluation_metrics.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b060c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, joblib\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "train = pd.read_csv(\"../data/processed/train.csv\")\n",
    "test = pd.read_csv(\"../data/processed/test.csv\")\n",
    "target = next((t for t in [\"target\",\"num\",\"condition\",\"disease\"] if t in train.columns), None)\n",
    "\n",
    "X_train, y_train = train.drop(columns=[target]), train[target]\n",
    "X_test, y_test = test.drop(columns=[target]), test[target]\n",
    "\n",
    "preprocessor = joblib.load(\"../models/preprocessor.pkl\")\n",
    "Xtr = preprocessor.fit_transform(X_train)\n",
    "Xte = preprocessor.transform(X_test)\n",
    "\n",
    "if hasattr(Xtr, \"toarray\"):\n",
    "    Xtr = Xtr.toarray()\n",
    "    Xte = Xte.toarray()\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=2000, random_state=RANDOM_STATE),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE),\n",
    "    \"SVM (RBF)\": SVC(probability=True, random_state=RANDOM_STATE),\n",
    "}\n",
    "\n",
    "metrics = []\n",
    "plt.figure()\n",
    "for name, clf in models.items():\n",
    "    clf.fit(Xtr, y_train)\n",
    "    y_pred = clf.predict(Xte)\n",
    "    y_prob = clf.predict_proba(Xte)[:,1] if hasattr(clf, \"predict_proba\") else None\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=\"binary\")\n",
    "    auc = roc_auc_score(y_test, y_prob) if y_prob is not None else float(\"nan\")\n",
    "\n",
    "    metrics.append([name, acc, prec, rec, f1, auc])\n",
    "\n",
    "    if y_prob is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "        plt.plot(fpr, tpr, label=f\"{name} (AUC={{auc:.3f}})\".format(auc=auc))\n",
    "\n",
    "plt.plot([0,1], [0,1], linestyle=\"--\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC Curves\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics, columns=[\"Model\",\"Accuracy\",\"Precision\",\"Recall\",\"F1\",\"AUC\"])\n",
    "metrics_df.sort_values(\"AUC\", ascending=False, inplace=True)\n",
    "print(metrics_df)\n",
    "\n",
    "with open(\"../results/evaluation_metrics.txt\", \"a\") as f:\n",
    "    f.write(\"\\\\n=== Baseline Models ===\\\\n\")\n",
    "    f.write(metrics_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
