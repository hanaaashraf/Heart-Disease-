{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27d70e1f",
   "metadata": {},
   "source": [
    "# 03 — Feature Selection\n",
    "\n",
    "Techniques:\n",
    "- Chi-Square (for categorical/positive features)\n",
    "- RFE (with LogisticRegression or RandomForest)\n",
    "- Model-based importances (RandomForest / XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3478f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, joblib\n",
    "from pathlib import Path\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "train = pd.read_csv(\"../data/processed/train.csv\")\n",
    "target = next((t for t in [\"target\",\"num\",\"condition\",\"disease\"] if t in train.columns), None)\n",
    "X_train, y_train = train.drop(columns=[target]), train[target]\n",
    "\n",
    "preprocessor = joblib.load(\"../models/preprocessor.pkl\")\n",
    "X_proc = preprocessor.fit_transform(X_train)\n",
    "if hasattr(X_proc, \"toarray\"):\n",
    "    X_proc = X_proc.toarray()\n",
    "\n",
    "# --- Chi2 (requires non-negative features) ---\n",
    "X_nonneg = MinMaxScaler().fit_transform(X_proc)\n",
    "k = min(10, X_nonneg.shape[1])\n",
    "skb = SelectKBest(chi2, k=k).fit(X_nonneg, y_train)\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(range(k), skb.scores_[np.argsort(skb.scores_)[-k:]])\n",
    "plt.title(\"Top-k Chi² Scores\")\n",
    "plt.xlabel(\"Feature Index (post-transform)\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.show()\n",
    "\n",
    "# --- RFE with Logistic Regression ---\n",
    "est = LogisticRegression(max_iter=2000, random_state=RANDOM_STATE)\n",
    "rfe = RFE(estimator=est, n_features_to_select=k).fit(X_proc, y_train)\n",
    "rfe_support = rfe.support_\n",
    "print(\"RFE selected features:\", np.where(rfe_support)[0][:k])\n",
    "\n",
    "# --- Model-based (RandomForest) ---\n",
    "rf = RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE)\n",
    "rf.fit(X_proc, y_train)\n",
    "importances = rf.feature_importances_\n",
    "top_idx = np.argsort(importances)[-k:]\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(range(k), importances[top_idx])\n",
    "plt.title(\"Top-k RF Importances\")\n",
    "plt.xlabel(\"Feature Index (post-transform)\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.show()\n",
    "\n",
    "# Save a simple mask (by RF top-k) for downstream use\n",
    "feature_mask = np.zeros(X_proc.shape[1], dtype=bool)\n",
    "feature_mask[top_idx] = True\n",
    "np.save(\"../models/feature_mask.npy\", feature_mask)\n",
    "print(\"Saved ../models/feature_mask.npy\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
